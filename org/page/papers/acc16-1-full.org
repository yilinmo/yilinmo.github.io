#+OPTIONS:   H:4 num:t toc:nil author:nil timestamp:nil tex:t 
#+BEGIN_EXPORT HTML
---
layout: page
title: ! 'Convex Optimization Based State Estimation against Sparse Integrity Attacks'
comments: true
---
#+END_EXPORT
--------------------------------
#+TOC: headlines 2 

* Introduction
  
  The concept of networks has been increasingly prevailing for decades, e.g., computer networks, sensor networks or social networks. Regardless of numerous benefits introduced by bridging machines or humans through networks, the interconnect and distributed nature renders networks vulnerable to various kinds of attacks, ranging from physical attacks to internet viruses to groundless rumors through online social networks. This article is concerned with the integrity attacks in sensor networks which are widely embedded in various industrial systems such as smart grid~\cite{MassoudAmin2005} or Supervisory Control And Data Acquisition (SCADA) systems~\cite{boyer2002scada}. During the integrity attack, the adversary can take full control of a subset of sensors and arbitrarily manipulate their measurements. The motivations for launching such an attack in industrial systems may include creating arbitrage opportunities in electricity market, stealing gas or oil without being noticed, posing potential threat to national defense, etc. Since the first SCADA system malware (called Stuxnet) was discovered and extensively investigated~\cite{Chen2010,Fidler2011}, increasing research attention has been paid to resolve the security issues in estimation and control systems~\cite{challengessecurity}.
  
  In this article, we focus on the problem of robust estimation against compromised sensory data in order to mitigate the damage caused by the integrity attack. Robustness for an estimator is urgently needed since quite a number of the commonly used estimators under attack fail to give a reliable estimate and thus lead to poor system performance. For instance, a linear estimator is not robust since one bad measurement is enough to ruin the final estimate. A better estimator may be the geometric median of all measurements~\cite{Lopuhaa1991}. To be concrete, we consider the problem of estimating a vector state \(x\in\mathbb R^n\) from measurements collected by \(m\) sensors, where the measurements are subject to any random noise. For practical reasons, the spatially distributed sensors cannot be fully guaranteed to be secure. Some of them may be controlled by the attacker and due to the resource limitation the attacker can only attack up to \( p  \) sensors. Without posing any restrictions on the attacker, we assume that the compromised sensory data can be arbitrarily changed.
  
** Related Work
A quite similar problem in the context of power systems is bad data detection, which has been studied over the past decades~\cite{Handschin1975,Mili1985}. The method of checking the magnitude of residue is useful for identifying random bad data or outliers but may not work for intentional integrity attacks \cite{henrik2010,Xie2011}. For example, Liu et al.~\cite{liu2009} successfully showed that a stealthy attack changing the state while not being detected is possible. Kim et al.~\cite{Kim2014} studied a so-called framing attack. Under such a attack, the bad data detector is misled to delete those critical measurements, without which the network is unobservable and a convert attack may be launched.
  
  For dynamical systems, detecting malicious components via fault detection and isolation based methods has also been extensively studied,  \cite{fp-ab-fb:09b,Pasqualetti2011,wirelesscontrol,Fawzi2012,chong2015observability}. However, in most of these works, the system is assumed to be noiseless, which greatly favors the failure detector. Pajic et al.~\cite{Pajic2014} improved the work by considering the systems with bounded noise. On the top of sufficient conditions for exact recovery in noiseless case, they showed that the worst error is still bounded even under attack. However, their estimator is based on a combinatorial optimization problem, which in general is computational hard to solve and may not be applicable for large scale systems. In \cite{Mo2010,moscs10security}, the authors use reachability analysis and ellipsoid approximation to characterize all possible biases the adversary can inject to the system.
  
  In the area of statistics, the concept of robust estimators is not new~\cite{Kassam1985,robust2006,robust2009}. The robustness is often measured by breakdown points~\cite{Hampel1971,donoho1983notion} or influence functions~\cite{Hampel1974}. Many existing works studied one or several estimators and discussed the breakdown point properties \cite{Yohai2012,Rousseeuw1992,Hossjer1994,Rousseeuw2012}. However, a unified analysis for most useful estimators is still absent.
  
  
  Motivated by different behaviors of various estimators under the integrity attacks, we manage to provide a unified robustness analysis framework integrating most commonly used estimators. To reach this goal, we first give a formal definition on the robustness of an estimator. To achieve greater generality, a general convex optimization based estimator is proposed and necessary and sufficient conditions on the robustness of such an estimator is proved. The significance of this work is that the analytical results presented in this manuscript can be used for characterizing and designing a robust estimator in the presence of compromised sensory data.
  
  
  The rest of the paper is organized as follows. In Section [[section:problemsetup]] we formulate the robust estimation problem. Our main results on the robustness of a general convex optimization based estimator is presented in Section [[section:main]]. We specialize our results for scalar sensor case in Section [[section:moreanalysis]]. The concluding remarks are given in Section [[section:conlusion]].
  
* Problem Setup 
<<section:problemsetup>>

** System Model
   Assume that \(m\) sensors are measuring the state \(x\) and the measurement equation for the \(i\)th sensor is given by
   
   \begin{align}
   \label{eq:goodsystem}
   z_i = H_i x + w_i,
   \end{align}
   
   where \(x\in\mathbb R^n\) is the state of interest, \(z_i\in \mathbb R^{m_i}\) is the ``true'' measurement collected by the \(i\)th sensor, and \(w_i \in \mathbb R^{m_i}\) is the measurement noise for the \(i\)th sensor. The measurement matrix \(H\triangleq [H_1^T,H_2^T,\ldots,H_i^T]^T\in\mathbb R^{(\sum_i m_i)\times n}\) is assumed to be observable, i.e., \(H\) is full column rank. In the presence of attacks, the measurement equation can be written as
   \begin{align}
   \label{eq:badsystem}
   y_i = z_i + a_i = H_i x + w_i + a_i,
   \end{align}
   where \(y_i\in \mathbb R^{m_i}\) is the ``manipulated'' measurement and \(a_i\in \mathbb R^{m_i}\) is the attack vector. In other words, the attacker can change the measurement of the \(i\)th sensor by \(a_i\). Denote
   \begin{align}
   z&\triangleq[z_1^T,z_2^T,\ldots,z_m^T]^T, &
   y&\triangleq[y_1^T,y_2^T,\ldots,y_m^T]^T, \\
   w&\triangleq[w_1^T,w_2^T,\ldots,w_m^T]^T,&
   a&\triangleq[a_1^T,a_2^T,\ldots,a_m^T]^T.\nonumber
   \end{align}
   
   Denote the index set of all sensors as \(\mathcal S\triangleq\{1,2,\ldots,m\}\). For any index set \(\mathcal I\subseteq \mathcal S\), define the complement set to be \(\mathcal I^c\triangleq \mathcal S\backslash\mathcal I\). In our attack model, we assume that the attacker can only compromise at most \(p\) sensors but can arbitrarily choose \(a_i\). Formally, a \((p,m)\)-sparse attack can be defined as
   
   #+BEGIN_DEFINITION
   *\((p,m)\)-sparse attack*: A vector \(a\) is called a \((p,m)\)-sparse attack if there exists an index set \(\mathcal I\subset \mathcal S\), such that:
   
  1. \(\left\|a_i\right\| = 0,~\forall i\in \mathcal I^c ;\)
  2. \(\left|\mathcal I\right| \leq p.\)
   #+END_DEFINITION
   
   Define the collection of a possible index set of malicious sensors as
   \[
   \mathbb C\triangleq\{\mathcal I:\mathcal I\subset\mathcal S,\left|\mathcal I\right| = p\}.
   \]
   The set of all possible \((p,m)\)-sparse attacks is denoted as
   \[
   \mathcal A \triangleq \bigcup_{\mathcal I\in\mathbb C}\{a: \left\|a_i\right\| = 0, i\in \mathcal I^c\}.
   \]
   
   The main task of this work is to investigate the generic sufficient and necessary conditions for an estimator to be robust to \((p,m)\)-sparse attacks. To this end, we first formally define the robustness of an estimator.
   
   #+BEGIN_DEFINITION
   *Robustness*: An estimator \(g:\mathbb R^{(\sum_i m_i)\times n}\mapsto \mathbb R^n\) which maps the measurements \(y\) to a state estimate \(\hat x\) is said to be robust to the \((p,m)\)-sparse attack if it satisfies the following condition:
   \begin{align}
   \left\|g(z)-g(z+a)\right\|\leq \mu(z),~\forall a\in\mathcal A,\label{eq:defrobust}
   \end{align}
   where \(\mu:\mathbb R^{(\sum_i m_i)\times n}\mapsto \mathbb R\) is a real-valued mapping on \(z\).
   #+END_DEFINITION
   
   The robustness implies that the disturbance on the state estimate caused by an arbitrary attack is bounded. A trivial robust estimator is \(g(y)=0\) which provides very poor estimate. Therefore, another desirable property for an estimator is translation invariance, which is defined as follows:
   
   #+BEGIN_DEFINITION
   *Translation invariance*: An estimator \(g\) is translation invariant if \(g(z+Hu)=u+g(z),~\forall u\in\mathbb R^n\).
   #+END_DEFINITION
   
   #+BEGIN_REMARK
   Notice that if an estimator is robust and translation invariant, then
   \begin{align*}
   \| g(z) - g(z+a) \|= \|x + g(w) - x + g(w+a) \|  = \|g(w)-g(w+a)\|\leq \mu(w).
   \end{align*}
   Therefore, the maximum bias that can be injected by an adversary is only a function of the noise \(w\).
   #+END_REMARK

   In the next subsection, we propose a general convex optimization based estimator which is translation invariant.
   
** A General Estimator
   A large variety of estimators are developed by the research community to solve the state estimation problem. In order to achieve greater generality, we first propose a general convex optimization based estimator. We then show that many estimators can be rewritten in this general framework.
   
   The estimator that we study in this paper is assumed to have the following form:
   \begin{align}
   \hat x = g(y) \triangleq \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S} f_i(y_i-H_i\hat x),
   \label{eq:general}
   \end{align}
   where the following properties of function \(f_i:\mathbb R^{m_i}\mapsto \mathbb R\) are assumed:
   
1. \(f_i\) is convex.
2. \(f_i\) is symmetric, i.e., \(f_i(u) = f_i(-u)\).
3. \(f_i\) is non-negative and \(f_i(0) = 0\).
   
#+NAME: remark:1 
#+ATTR_HTML: :id remark:1
#+BEGIN_REMARK
It is easy to check that the estimator \(g\) is translation invariant. One can view \(y_i-H_i\hat x\) as the residue for the \(i\)th sensor and \(f_i\) as a cost function. The convex constraints on \(f_i\) ensures that the minimization problem can be solved in an efficient (possibly also distributed) way. The symmetric assumption on \(f_i\) is typically true for many practically used estimator and can actually be relaxed. The last assumption implies that the cost achieves minimum value when the residue is \(0\).
#+END_REMARK

We now investigate several commonly used estimator and show that they can be written as \eqref{eq:general}.

- Least Square Estimator:
\begin{align}
\hat x &=  \mathop{argmin}_{\hat x} \left\|y-H\hat x\right\|_2^2=  \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S}\left\|y_i-H_i\hat x\right\|_2^2\nonumber\\
& = (H^T H)^{-1}H^T y.
\label{eq:lsestimator}
\end{align}
- Another example is an estimator which minimizes the sum of the \(l_1\) norm of the residue, i.e.,
\begin{align}
\hat x = \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S}\left\|y_i-H_i\hat x\right\|_1.  \label{eq:medianestimator}
\end{align}
In the case that \(m_i=n\) and \(H_i=I_n,~\forall i\), the estimate is a vector in which the \(i\)th entry is the median over the \(i\)th entries of all measurements \(y_i\)'s.

- The following is designed to minimize the sum of the \(l_2\) norm of the residue:
\begin{align}
\hat x = \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S}\left\|y_i-H_i\hat x\right\|_2.  
\label{eq:geometricmedianestimator}
\end{align}
The optimal estimate in the case that \(m_i=n\) and \(H_i=I_n,~\forall i\) is the geometric median of all \(y_i\)'s, which is called an \(L_1\) estimator in \cite{Lopuhaa1991}. In other words, \(\hat x\) is the point in \(\mathbb R^n\) that minimizes the sum of Euclidean distances from \(y_i\) to that point.
- Pajic et al.~\cite{Pajic2014} proposed the following robust estimator in the presence of integrity attack:
\begin{align*}
& \mathop{\textit{minimize}}\limits_{\hat x,a,w}&
& \|w\|^2\\
&\text{subject to}&
&y = H\hat x + w + a,\,\|a\|_0\leq q.
\end{align*}
However, the minimization problem involves zero-norm, and thus is difficult to solve in general. A commonly adopted approach is to use \(L_1\) relaxation to approximate zero-norm, which leads to the following minimization problem:
\begin{align}
& \mathop{\textit{minimize}}\limits_{\hat x,a,w}&
& \|w\|^2+\lambda \|a\|_1\label{eq:optlasso}\\
&\text{subject to}&
&y = H\hat x + w + a.\nonumber
\end{align}
If we define the following function:
\begin{align}
d(u)~\triangleq ~&\mathop{\textit{minimize}}\limits_{a_i}&
&  \left\|u-a_i\right\|_2^2 + \lambda  \left\|a_i\right\|_1 \label{eq:lasso2}
\end{align}
Then one can easily prove that the optimization problem \eqref{eq:optlasso} can be rewritten as
\begin{align}
\hat x = \mathop{argmin}_{\hat x} \sum_{i\in\mathcal I} d(y_i - H_i \hat x).\label{eq:lasso}
\end{align}

In the next section, we shall present sufficient and necessary conditions for the robustness of the general estimator \eqref{eq:general}. Since \eqref{eq:medianestimator}, \eqref{eq:geometricmedianestimator} and \eqref{eq:lasso} are all special cases of \eqref{eq:general}, we can easily analyze their individual robustness.


* Robust Analysis for a General Estimator 
  <<section:main>>
  This section is devoted to the derivation of necessary and sufficient conditions for the robustness of the general estimator.

  Denote the compact set \(\mathcal U\triangleq\{u\in \mathbb R^n:\left\|u\right\|= 1\}\). Before proceeding to the main results, we need the following lemma.

  #+NAME: lemma:convex
  #+ATTR_HTML: :id lemma:convex
  #+BEGIN_LEMMA
  Let \(q:\mathbb R\rightarrow \mathbb R\) be a convex function and \(q(0) = 0\), then \(q(t)/t\) is monotonically non-decreasing on \(t\in \mathbb R^+\). Moreover,
  \begin{align}
  q(t+1)-q(t)\geq q(t)/t.
  \label{eq:marginalincrease}
  \end{align}
  #+END_LEMMA

  #+BEGIN_PROOF
  For any \(0 < \alpha < 1\), we have
  \begin{align*}
  q(\alpha t) \leq \alpha q(t) + q(0) = \alpha q(t).
  \end{align*}
  Divide both side by \(\alpha t\), we can prove that \(q(t)/t\) is monotonically non-decreasing. Therefore, \(q(t+1)/(t+1)\geq q(t)/t\), which implies \eqref{eq:marginalincrease}.
  #+END_PROOF
  As a consequence of Lemma [[lemma:convex]], we know that \(f_i(tH_iu)/t\) is monotonically non-decreasing. As a result, there are only two possibilities:
  
1. \(f_i(tH_iu)/t\) is bounded for all \(i\) and for all \(u\), which implies that the limit \(\lim_{t\rightarrow\infty}f_i(tH_iu)/t\) exists.
2. \(f_i(tH_iu)/t\) is unbounded for some \(i\) and \(u\).
   
The next lemma provides several important properties for the case where \(\lim_{t\rightarrow\infty}f_i(tH_iu)/t\) exists, whose proof is reported in the appendix:

#+NAME: lemma:1
#+ATTR_HTML: :id lemma:1
#+BEGIN_LEMMA
If the following limit is well defined, i.e., finite, for all \(u\in \mathbb R^{n}\):
\begin{align}
\lim_{t\rightarrow\infty} \frac{f_i(tH_iu)}{t} = C_i(u),
\label{eq:sublinear}
\end{align}
then the following statements are true:

- \(C_i(\alpha u)=\left|\alpha\right| C_i(u)\) and \(C_i(u_1+u_2)\leq C_i(u_1)+C_i(u_2)\).
- Define the function \(h_i(u,v,t):\mathbb R^n\times\mathbb R^{m_i}\times \mathbb R\mapsto\mathbb R\),
\begin{align}
h_i(u,v,t) \triangleq \frac{1}{t}\left[f_i(v+tH_iu)-f_i(v)\right].\label{eq:defhfunction}
\end{align}
Then the following pointwise limit holds:
\begin{align}
\lim_{t\rightarrow\infty}h_i(u,v,t)  = C_i(u).
\label{eq:deltalimit}
\end{align}
Moreover, the convergence is uniform on any compact set of \((u,v)\).
- For any \(v\) and \(u\), we have that
\begin{align}
f_i(v+H_iu) - f_i(v) \leq C_i(u).
\label{eq:deltaw}
\end{align}

#+END_LEMMA

#+NAME: remark:force
#+ATTR_HTML: :id remark:force
#+BEGIN_REMARK
Intuitively speaking, one can interpret \(f_i\) as a potential field and the derivative of \(f_i\) as the force generated by sensor \(i\) (if it is differentiable). By \eqref{eq:deltaw}, we know that the force from the potential field \(f_i\) along the \(u\) direction cannot exceed \(C_i(u)\) (or \(C_i(u)/\|u\|\) to normalize). On the other hand, Equation \eqref{eq:deltalimit} implies that this bound is achievable.
#+END_REMARK

We now give the sufficient condition for the robustness of the estimator.

#+NAME: theorem:sufficient
#+ATTR_HTML: :id theorem:sufficient
#+BEGIN_THEOREM
 If the following conditions hold:

- \(C_i(u)\) is well defined for all \(u\in \mathbb R^{n}\) and all \(i\in\mathcal S\);
- the following inequality holds for all non-zero \(u\):
\begin{align}
\sum_{i\in\mathcal I}C_i(u)<\sum_{i\in\mathcal I^c}C_i(u),~\forall \mathcal I \in\mathbb C,\label{eq:sufficiency}
\end{align}

then the estimator \(g\) is robust.
#+END_THEOREM

#+BEGIN_PROOF
Our goal is to prove that there exists a \(\beta(z)\), such that for any \(t\geq \beta(z)\), \(\|u\| = 1\), \(a\in\mathcal A\), the following inequality holds:
\begin{align}
\sum_{i\in\mathcal S}f_i(y_i - H_i\times tu) < \sum_{i\in\mathcal S} f_i(y_i-H_i\times (t+1)u).
\label{eq:sufficientdiff}
\end{align}
As a result, any point \(\|\hat x\| \geq \beta(z)+1\) cannot be the solution of the optimization problem since there exists a better point \((\|\hat x\|-1)\hat x/\|\hat x\|\). Therefore, we must have \(\|g(y)\|\leq \beta(z) + 1\) and hence the estimator is robust.

Suppose the set of malicious sensors is \(\mathcal I\), to prove \eqref{eq:sufficientdiff}, we will first look at benign sensors. Due to the uniform convergence of \(h_i(u,v,t)\) to \(C_i(u)\) on \(\mathcal U\times\{-z_i\}\) shown in Lemma [[lemma:1]], given any \(\delta>0\) we can always find a finite constant \(N_i\) depending on \(\delta\) and \(z_i\) such that for all \(t \geq N_i(\delta,z_i)\), the following inequality holds:
\begin{align}
h_i(-z_i,u,t) = \frac{1}{t}\left[f_i(tH_iu-z_i)-f_i(-z_i)\right]\geq C_i(u) - \delta,
\label{eq:deltaapprox2}
\end{align}
for any \(\|u\|=1\). By \eqref{eq:marginalincrease}, we can derive that
\begin{align}
f_i((t+1)H_iu-z_i)-f_i(tH_iu-z_i)\geq C_i(u) - \delta.
\label{eq:deltaapprox3}
\end{align}
We define \(\beta(z) \triangleq \max_{1\leq i\leq m} N_i(\delta,z_i)\) and fix \(\delta\) to be
\begin{align}
\delta = \frac{1}{m}\min_{\|u\|=1}\min_{\mathcal I\in\mathbb C}\left(\sum_{i\in\mathcal I^c}C_i(u) - \sum_{i\in\mathcal I}C_i(u)\right).\label{eq:defdelta}
\end{align}
Notice that we write \(\min_{\|u\|=1}\) instead of \(\inf_{\|u\|=1}\) since \(C_i(u)\) is continuous and the set \(\{u:\|u\|=1\}\) is compact. Hence, the infimum is achievable, which further proves that \(\delta > 0\) is strictly positive. Hence, for \(i = 1,\dots,m\), if \(t > \beta_{\delta}(z)\) we have
\begin{equation}
f_i((t+1)H_iu-z_i)-f_i(tH_iu-z_i) \geq C_i(u) - \delta,\,\forall \|u\|=1.
\end{equation}
Since for good sensors, \(z_i = y_i\), we know that
\begin{align}
\sum_{i\in \mathcal I^c} & \left[f_i((t+1)H_iu-z_i)-f_i(tH_iu-z_i)\right]\nonumber\\
&\geq  \sum_{i\in \mathcal I^c} C_i(u) -(m-p) \delta,\,\forall \|u\|=1.
\label{eq:suff2}
\end{align}
We now consider malicious sensors. By Lemma [[lemma:1]] (iii), we know that for \(i\in\mathcal I\), and any \(u\)
\begin{align}
\sum_{i\in\mathcal I} f_i(y_i - t H_i u)  - \sum_{i\in\mathcal I} f_i(y_i- (t +1)H_i u)\leq \sum_{i\in\mathcal I}C_i(-u).\label{eq:suff1}
\end{align}
Hence from \eqref{eq:defdelta}, \eqref{eq:suff1} and \eqref{eq:suff2}, we know that
\begin{align*}
\sum_{i\in\mathcal S} f_i(y_i &- (t+1) H_i u) - \sum_{i\in\mathcal S} f_i(y_i - t H_i u) \\
&\geq \sum_{i\in\mathcal I^c}C_i(u) - \sum_{i\in\mathcal I}C_i(u) - (m-p)\delta > 0,
\end{align*}
which proves \eqref{eq:sufficientdiff}.
#+END_PROOF

#+BEGIN_REMARK
Assuming that \(y_i\) is a scalar and \(w=0\), Fawzi et al.~\cite{Fawzi2012} prove that the state can be exactly recovered under the integrity attack if and only if for all \(u\neq 0\), there are at least \(2p+1\) non-zero \(H_iu\). Notice that if for some \(u\neq 0\), there are less than \(2p+1\) non-zero \(H_iu\), then we can choose \(\mathcal I\) to contain the largest \(p\) \(H_iu\) and thus violate \eqref{eq:sufficiency}. As a result, our sufficient condition is stronger than the ones proposed in \cite{Fawzi2012}. The main reason is that we seek to use convex optimization to solve the state estimation problem, while in \cite{Fawzi2012}, a combinatorial optimization problem is needed to recover the state.
#+END_REMARK

We next give necessary conditions for the robustness of the estimator.

#+NAME: theorem:necessity1
#+ATTR_HTML: :id theorem:necessity1
#+BEGIN_THEOREM
*Necessary Condition I*: If \( C_i(u)\) is well defined for all \(u\in \mathbb R^{n}\) and all \(i\in\mathcal S\) but there exist some \(\|u_0\|=1,~\mathcal I_0\in\mathbb C\) such that
\begin{align}
\sum_{i\in\mathcal I_0}C_i(u_0)>\sum_{i\in\mathcal I_0^c}C_i(u_0),\label{eq:necessity}
\end{align}
then the estimator is not robust to the attack.
#+END_THEOREM

#+BEGIN_PROOF
The robustness of the estimator is equivalent to that the optimal estimate \(\hat x\) satisfies \(\left\|\hat x\right\|\leq \mu(z)\) for all \(a\in \mathcal A\), where \(\mu\) is a real-valued function. To this end, we will prove that for any \(r > 0\), there exists a \(y\) such that all \(\hat x\) that satisfies \(\left\|\hat x\right\|\leq r\) cannot be the optimal solution of \eqref{eq:general}.

We will first look at the compromised sensors. For every \(\delta>0\) we can always find a finite constant \(N_i(\delta)\) such that for any \(\hat x\in\{\hat x:\left\|\hat x\right\|\leq r\}\) and for all \(t > N_i\), the following inequality holds:
\begin{align}
&f_i(t H_iu_0-H_i\hat x)-f_i(tH_iu_0 - H_i(\hat x+u_0)) \nonumber\\
&f_i((t+1) H_iu_0-H_i(\hat x+u_0))-f_i(tH_iu_0 - H_i(\hat x+u_0)) \nonumber\\
\geq & h_i(u_0,-H_i(\hat x+u_0),t)\geq C_i(u_0)-\delta,~\forall i\in \mathcal I_{0}. \label{eq:nece1}
\end{align}
The first inequality is derived from \eqref{eq:marginalincrease}. The second inequality is due to the uniform convergence of \(h_i(u,v,t)\) to \(C_i(u)\) on \(\{u_0\}\times \{v:v=-H_ix+u_0,\,\|x\|\leq  r\}\).

Let us choose
\begin{align*}
\delta = \frac{1}{m}\left(\sum_{i\in\mathcal I_{0}}C_i(u_0) - \sum_{i\in \mathcal I_{0}^c}C_i(u_0)\right),
\end{align*}
and \(t = \max_{i\in\mathcal I_0} N_i(\delta)\) and \(y_i = tH_iu_0\) for all \(i\in \mathcal I_0\), then we know for any \(\|\hat x\|\leq  r\),
\[
\sum_{i\in\mathcal I_0}\left[f_i(y_i-H_i\hat x)-f_i(y_i - H_i(\hat x+u_0))\right]  \geq \sum_{i\in \mathcal I_0} C_i(u_0)-p\delta.
\]
Now let us look at the benign sensors. By Lemma [[lemma:1]] (iii) we have
\begin{equation}
f_i(z_i-H_i(\hat x+u_0))-f_i(z_i-H_i\hat x)  \leq  C_i(u_0),~\forall i\in \mathcal I\backslash \mathcal I_{m_0}.\label{eq:nece2}
\end{equation}
From \eqref{eq:nece1} and \eqref{eq:nece2},
\begin{equation}
\sum_{i\in\mathcal S} f_i(y_i-H_i(\hat x+u_0))  - \sum_{i\in\mathcal S} f_i(y_i-H_i\hat x) \leq \sum_{i\in\mathcal I_0^c}C_i(u_0) - \sum_{i\in\mathcal I_{0}}C_i(u_0) + p\delta < 0.
\end{equation}
Thus for such a \(y\) satisfying
\begin{align*}
 y_i= \left\{
\begin{array}{ll}
z_i, & \hbox{if } i\in\mathcal I_0^c\\
tH_iu_0, & \hbox{if } i\in\mathcal I_{0},
\end{array}
\right.
\end{align*}
\(\hat x+u_0\) is a better estimate than all \(\hat x\) satisfying \(\left\|\hat x\right\|\leq  r\). Since \(r\) is an arbitrary positive real number, we can conclude that the estimator is not robust.
#+END_PROOF

#+NAME: theorem:necessity2
#+ATTR_HTML: :id theorem:necessity2
#+BEGIN_THEOREM
*Necessary Condition II*: If there exists \(u_0 \in \mathbb R^{n}\) and \(j\in \mathcal I\) such that
\begin{align}
\lim_{t\rightarrow\infty} \frac{f_i(tH_iu_0)}{t}\rightarrow +\infty,
\label{eq:sublinear2}
\end{align}
then the estimator is not robust to the attack.
#+END_THEOREM
Before proving Theorem [[theorem:necessity2]], we need the following lemma whose proof is reported in appendix.

#+NAME: lemma:divergence
#+ATTR_HTML: :id lemma:divergence
#+BEGIN_LEMMA
If the condition \eqref{eq:sublinear2} holds, for any \(M>0\) and for all \(v\) in a compact set \(\mathcal V\subset \mathbb R^{m_i}\), there exists \(N\) (depending on \(M\) and the set \(\mathcal V\)) such that the following inequality holds:
\begin{align}
h_j(u_0,v,t)>M,\,\forall v\in \mathcal V\label{eq:divergence}
\end{align}
#+END_LEMMA

Now we are ready to prove the theorem.

#+BEGIN_PROOF
Similar to Theorem [[theorem:necessity1]], we will prove that for any \(r > 0\), there exists a \(y\) such that all \(\hat x\) that satisfies \(\left\|\hat x\right\|\leq r\) cannot be the optimal solution of \eqref{eq:general}.

We first look at any sensor \(i\), where \(i\neq j\). Since a continuous function achieves its supremum on a compact set, we know that the following supremum is well defined (not infinite)
\begin{align*}
\sup_{\|\hat x\|\leq r}\left[f(z_i - H_i(\hat x+u_0)) - f(z_i - H_i\hat x)\right] = M_i,
\end{align*}
which implies that for all \(\|\hat x\|\leq r\), we can find \(M > 0\), such that
\begin{align}
\sum_{i\neq j} f(z_i - H_i(\hat x+u_0)) - \sum_{i\neq j} f(z_i - H_i\hat x) \leq M.
\label{eq:divergence1}
\end{align}

Now let us consider sensor \(j\). Due to Lemma [[lemma:divergence]], we can find a \(t\), such that for all \(\|\hat x\|\leq r\), the following inequality holds:
\begin{align*}
h_j(u_0,-H_j(\hat x + u_0),t) > M.
\end{align*}

Using Lemma [[lemma:convex]], we have
\begin{align}
&f((t+1)H_ju_0 - H_j(\hat x + u_0)) - f(t H_ju_0 - H_j(\hat x + u_0))\nonumber\\
& = f(tH_ju_0 - H_j\hat x) - f(t H_ju_0 - H_j(\hat x + u_0))\nonumber\\
& \geq h_j(u_0,-H_j(\hat x + u_0),t) > M.\label{eq:divergence2}
\end{align}
Now consider the following \(y\)
\begin{align*}
 y_i= \left\{
\begin{array}{ll}
z_i, & \hbox{if } i\neq j\\
tH_ju_0, & \hbox{if } i=j,
\end{array}
\right.
\end{align*}

Combining \eqref{eq:divergence1} and \eqref{eq:divergence2}, we know that for all \(\|\hat x\|\leq r\), the following inequality holds
\begin{align*}
\sum_{i\in\mathcal S} f(y_i - H_i(\hat x+u_0)) - \sum_{i\in\mathcal S} f(y_i - H_i\hat x) < M - M =0,
\end{align*}
which implies that the optimal solution of \eqref{eq:general} cannot be inside the ball \(\{\hat x:\|\hat x\|\leq r\}\). Now since \(r > 0\) is arbitrary, we know the estimator is not robust.
#+END_PROOF
Before continuing on, we would like to provide some remarks on the main result. First, it is worth noticing that the existence of a well defined limit of \(f_i(tH_iu)/t\) is crucial for the robustness of \(g\) as Theorem [[theorem:necessity2]] suggested. For example, the least square estimator cannot be robust since \(f_i\) is in quadratic form. Using the potential field and force analogies in Remark [[remark:force]], one can interpret the results presented in this section as: the estimator \(g\) is robust if the force generated by any sensor is bounded and if the combined force of any collection of \(p\) sensors is no greater than the combined force of the remaining \(m-p\) sensors.

Secondly, one can see that the conditions proved in Theorem [[theorem:sufficient]], [[theorem:necessity1]] and [[theorem:necessity2]] are very tight, with only a trivial gap where the LHS of \eqref{eq:necessity} equals the RHS.

Finally, we want to point out that the condition \eqref{eq:sufficiency} is non-trivial to check since it requires us to verify against all possible \(u\). In the next subsection, we consider a special case where each \(y_i\) is a scalar and provide a more conservative but verifiable sufficient condition for the robustness of the estimator.

* Scalar Measurement Case: More Analysis
  <<section:moreanalysis>>
  In this section, we specialize our results to the scalar measurement case, i.e., \(m_i=1,~\forall i\in \mathcal S\). Throughout this section, we assume that the following limit is well-defined:
  \begin{align}
  \alpha_i \triangleq \lim_{t\rightarrow\infty} f_i(t)/t.
  \end{align}
  It is not difficult to prove that \(C_i(u) = \left|\alpha_i H_i u\right|\). With slight abuse of notation, define \(C_i \triangleq \alpha_i H_i\), then \(C_i(u) = \left|C_iu\right|\). For any index set \(\mathcal I = \{i_1,\dots,i_l\}\subset \mathcal S\), define
  \begin{align}
  C_{\mathcal I} \triangleq \begin{bmatrix}
  C_{i_1}\\
  \vdots\\
  C_{i_l}
  \end{bmatrix}.
  \end{align}
  
  From Theorem [[theorem:sufficient]] and Theorem [[theorem:necessity1]], we have the following sufficient and necessary conditions for robustness of \(g\).

  #+NAME: prop:scalarsuffandnece
  #+ATTR_HTML: :id prop:scalarsuffandnece
  #+BEGIN_PROPOSITION
  - If for all possible index set \(\mathcal I\) and all non-zero \(u\in\mathbb R^n\) the following inequality holds: 
  \begin{align}
  \|C_{\mathcal I}u\|_1= \sum_{i\in\mathcal I}|C_{i} u |<  \sum_{i\in\mathcal I^c}|C_{i} u| = \|C_{\mathcal I^c}u\|_1, \label{eq:suff3}
  \end{align}
  then the estimator \(g\) is robust.
  - If there exists an index set \(\mathcal I\) and a \(u\in\mathbb R^n\) such that the following inequality holds: 
  \begin{align}
  \|C_{\mathcal I}u\|_1 > \|C_{\mathcal I^c}u\|_1, \label{eq:suff4}
  \end{align}
  then the estimator \(g\) is not robust.
  #+END_PROPOSITION
  
  The main difficulty here is to validate \eqref{eq:suff3} for all non-zero \(u\). In the next theorem, we can find a more conservative but more practically useful sufficient condition for the robustness, by eliminating \(u\) from \eqref{eq:suff3}.
  
  #+NAME: theorem:scalarsuff
  #+ATTR_HTML: :id theorem:scalarsuff
  #+BEGIN_THEOREM
  If for any index set \(\mathcal I\subset \mathcal S\) with cardinality \(p\), the optimal value of the following optimization problem is strictly less than \(1\):
  \begin{align}
  &\mathop{\textrm{minimize}}\limits_{K\in\mathbb R^{n\times{(m-p)}}}&
  & \|C_{\mathcal I}K\|_1\nonumber\\
  &\textrm{subject to}&
  & KC_{\mathcal I^c} = I_n,\label{eq:scalarsufficient}
  \end{align}
  then the estimator \(g\) is robust.
  #+END_THEOREM
  
  #+BEGIN_PROOF
  Let \(K\in\mathbb R^{n\times (m-p)}\) such that \(K C_{\mathcal I^c} = I_n\). Denote \(\xi=C_{\mathcal I^c} u\). We have \(C_{\mathcal I} u = C_{\mathcal I} K \xi\). Therefore, if for all \(\xi\neq 0\), \(\left\|C_{\mathcal I}\right\| K \xi_1 < \left\|\xi\right\|_1\), i.e., \(\left\|C_{\mathcal I}\right\|K_1 < 1\), then
  \begin{align*}
  \|C_{\mathcal I}u\|_1 <  \|C_{\mathcal I^c}u\|_1.
  \end{align*}
  By enumerating all possible \(\mathcal I\) we can conclude the proof.
  #+END_PROOF
  
  Notice that \eqref{eq:scalarsufficient} is not necessary. Since \(\xi\) is in the column space of \(C_{\mathcal I^c}\), \(\xi\) may not be able to take all possible value in \(\mathbb R^{m-p}\).
  
  Similarly, we can find a more practically useful version for the necessary condition implied by Theorem [[theorem:necessity1]]. By enumerating all \((C_{\mathcal I},C_{\mathcal I^c})\) and utilizing the following result, we can identify whether \(g\) is robust for a given \(H\) or not.

  #+NAME: theorem:scalarnecessity
  #+ATTR_HTML: :id theorem:scalarnecessity
  #+BEGIN_THEOREM
  If there exists an index set \(\mathcal I\) such that the following inequality holds:
  \begin{align}
  \|C_{\mathcal I}C_{\mathcal I^c}^+\|_1 > (\sqrt{m-p}+1)/2,\label{eq:nece3}
  \end{align}
  where \(C_{\mathcal I^c}^+\) is the Moore-Penrose pseudo inverse of \(C_{\mathcal I^c}\), then the estimator \(g\) is not robust.
  #+END_THEOREM
  The following lemma, whose proof is given in the appendix, is needed for the proof of Theorem [[theorem:scalarnecessity]]:

  #+NAME: lemma:l1decompose
  #+ATTR_HTML: :id lemma:l1decompose
  #+BEGIN_LEMMA
  Let \(\xi\in\mathbb R^m\) such that \(\xi = \xi_{\parallel} + \xi_{\perp}\), where \(\xi_{\|}\) and \(\xi_\perp\) are perpendicular to each other. Then the following inequality holds:
  \begin{align}
  \|\xi_\|\|_1 \leq \frac{\sqrt{m}+1}{2}\|\xi\|_1.
  \label{eq:parallel}
  \end{align}
  Moreover, the above inequality is achievable when
  \begin{align*}
  \xi =  \begin{bmatrix}
  1\\
  0\\
  \vdots\\
  0
  \end{bmatrix}, \,\xi_\|=\frac{1}{2}\begin{bmatrix}
  1+m^{-1/2}\\
  m^{-1/2}\\
  \vdots\\
  m^{-1/2}
  \end{bmatrix}, \,\xi_\perp=\frac{1}{2}\begin{bmatrix}
  1-m^{-1/2}\\
  -m^{-1/2}\\
  \vdots\\
  -m^{-1/2}
  \end{bmatrix}.
  \end{align*}
  #+END_LEMMA
  
  
  We are now ready to prove Theorem [[theorem:scalarnecessity]]:
  #+BEGIN_PROOF
  To prove \(g\) is not robust, from Proposition [[prop:scalarsuffandnece]] we only need to show there exists a \(u\) such that \(\|C_{\mathcal I}u\|_1 > \|C_{\mathcal I^c} u\|_1\) if \eqref{eq:nece3} holds.
  Since \(\left\|C_{\mathcal I}C_{\mathcal I^c}^+\right\|_1>(\sqrt{m-p}+1)/2\), we can find \(\xi\in \mathbb R^{m-p}\), such that
  \begin{align*}
  \left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi\right\|_1 >\frac{\sqrt{m-p}+1}{2}\left\|\xi\right\|_1.
  \end{align*}
  
  Now we can decompose \(\xi = \xi_\|+\xi_\perp\), where \(\xi_\|\) belongs to the column space of \(C_{\mathcal I^c}\) and \(\xi_\perp\) is perpendicular to the column space of \(C_{\mathcal I^c}\). By the property of Moore-Penrose inverse, \(C_{\mathcal I^c}^+\xi_\perp = 0\). Therefore,
  \begin{align*}
  \left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi\right\|_1 = \left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi_\|\right\|_1.
  \end{align*}
  On the other hand, since \(\xi\in \mathbb R^{m-p}\), by Lemma [[lemma:l1decompose]], we have
  \begin{align*}
  \frac{\sqrt{m-p}+1}{2}\left\|\xi\right\|_1\geq \left\|\xi_\|\right\|_1,
  \end{align*}
  which implies that
  \begin{align*}
  \left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi_\|\right\|_1 >\left\|\xi_\|\right\|_1.
  \end{align*}
  Since \(\xi_\|\) belongs to the column space of \(C_{\mathcal I^c}\), there exists a \(u\), such that \(C_{\mathcal I^c} u = \xi_\|\). Therefore, we can find a \(u\), such that
  \begin{align*}
  \left\|C_{\mathcal I}u\right\|_1 > \left\|C_{\mathcal I^c}u\right\|_1,
  \end{align*}
  which completes the proof.
  #+END_PROOF
  
* Concluding Remarks 
  <<section:conlusion>>
We have studied the robust estimation problem where \(p\) out of \(m\) sensors are under attack. The malicious measurements can be arbitrarily manipulated and thus a robust estimator which can give a reliable estimate is needed. Our interest is not to study any concrete estimator in presence of attacks. Instead, we have considered a general class of estimators which integrate a large number of important estimators as special cases and given sufficient and necessary conditions for the robustness of the estimator. Moreover, we have presented more analytical results in the scalar measurement case to render the sufficient and necessary conditions more ready to use. Future works include the robustness analysis for the dynamical state estimation problem.
* Appendix
** Proof of Lemma [[lemma:1]]
   
   - If \(\alpha = 0\), then clearly \(C_i(0)= 0\). On the other hand, if \(\alpha\neq 0\), from the definition in \eqref{eq:sublinear}, we have
   \begin{align*}
   C_i(\alpha u) &= \lim_{t\rightarrow\infty} \frac{1}{t}f_i(|\alpha|t H_i u)\\
   &= \left|\alpha\right| \lim_{t\rightarrow\infty} \frac{1}{\left|\alpha\right| t}f_i(|\alpha| t H_i u)= \left|\alpha\right| C_i(u).
   \end{align*}
   Due to the scaling property of \(C_i(u)\) and the convexity of \(f_i\), we have
   \begin{align*}
   C_i(u_1+u_2)= 2C_i\left(\frac{u_1+u_2}{2}\right)\leq C_i(u_1) + C_i(u_2).
   \end{align*}
   Therefore, we know that \(C_i\) is actually a semi-norm on \(\mathbb R^n\)
   - Based on the convexity of \(f_i\), we obtain
   \begin{align}
   2f_i(\frac{tH_iu}{2})&\leq f_i(v+tH_iu) + f_i(-v),\label{eq:temp1}\\
   f_i(tH_iu)&\geq 2f_i(\frac{2v+tH_iu}{2}) - f(2v).\label{eq:temp2}
   \end{align}
   Dividing both sides of \eqref{eq:temp1} and \eqref{eq:temp2} by \(t\) and taking limit over \(t\), we have
   \begin{align}
   C_i(u)&\leq \liminf_{t\rightarrow\infty}\frac{1}{t}f_i(v+tH_iu) +   \lim_{t\rightarrow\infty}\frac{1}{t}f_i(-v),\label{eq:liminf}\\
   C_i(u)&\geq \limsup_{t\rightarrow\infty}\frac{2}{t}f_i(v+\frac{t}{2}H_iu) -   \lim_{t\rightarrow\infty}\frac{1}{t}f_i(2v).\label{eq:limsup}
   \end{align}
   Since \(\lim_{t\rightarrow\infty}f_i(-v)/t=\lim_{t\rightarrow\infty}f_i(2v)/t=0\), from \eqref{eq:limsup} and \eqref{eq:liminf} we have the following pointwise limit
   \begin{align*}
   \lim_{t\rightarrow\infty}h_i(u,v,t) = C_i(u).
   \end{align*}
   Notice that for a fixed \((u,v)\), by Lemma [[lemma:convex]], \(h(u,v,t)\) is monotonically non-decreasing with respect to \(t\). Furthermore, \(C_i(u)\) is continuous since it is a semi-norm. Therefore, by Dini's theorem~\cite{rudin1964principles}, \(h(u,v,t)\) converges uniformly to \(C_i(u)\) on a compact set of \((u,v)\).
   - By Lemma [[lemma:convex]], we have
   \[
   f_i(v+H_iu)-f_i(v) = f_i(H_iu) \leq \lim_{t\rightarrow} \frac{f_i(tH_iu)}{t} = C_i(u).
   \]
   
** Proof of Lemma [[lemma:divergence]]

  From \eqref{eq:sublinear2} and \eqref{eq:temp1}, it is easy to see that \(h_j(u_0,v,t)\) diverges to infinity for all \(v\), i.e.,
  \begin{align}
    h_j(u_0,v,t)\rightarrow +\infty.\label{eq:temp3}
  \end{align}
  Next we will show this divergence is also uniform. Denote \(\mathcal W_t\triangleq\{v:h_j(u_0,v,t)>M\}\). Since \(h_j(u_0,v,t)\) is continuous (\(f_i\) is continuous due to convexity), each \(\mathcal W_t\) is open. By Lemma [[lemma:convex]], \(h_j(u_0,v,t)\) is monotonically non-decreasing in \(t\). Therefore, \(\mathcal W_t\subseteq \mathcal W_{t'}\) if \(t\leq t'\) . Since for each \(v\) there exists \(t\) such that \(h_j(u_0,v,t)>M\) from \eqref{eq:temp3},
  \begin{align*}
    \bigcup_{t\geq 0}\mathcal W_t = \mathbb R^{m_i}.
  \end{align*}
  Therefore, the collection \(\{\mathcal W_t\}\) is an open cover for the compact subset \(\mathcal V\). Thus, we can find a finite cover \(\mathcal W_{t_1},\dots,\mathcal W_{t_l}\) that covers \(\mathcal V\), i.e.,
  \begin{align}
    \mathcal V\subseteq \mathcal W_{t_1} \cup\mathcal W_{t_2} \cup\dots\cup \mathcal W_{t_l} .
    \label{eq:opencover}
  \end{align}
  Now we can define \(N = \max(t_1,\dots,t_l)\). Since \(\mathcal W_t\) is non-decreasing with respect to \(t\), the RHS of \eqref{eq:opencover} is \(\mathcal W_N\). For any \(t \geq N\), we have
  \begin{align*}
    \mathcal V\subseteq \mathcal W_{N}\subseteq \mathcal W_t,
  \end{align*}
  which combined with the definition of \(\mathcal W_t\) finishes the proof. 

** Proof of Lemma [[lemma:l1decompose]]
   
   Geometrically, \(\xi_{\|}\) can be written as \(\xi_{\|}=\xi/2 + r\), where \(r\in\{r:\|r\|_2 = \|\xi\|_2 /2\}\). As a result, we have
   \[
   \|\xi_\|\|_1 \leq \frac{1}{2}\|\xi\|_1 + \|r\|_1 \leq \frac{1}{2}\|\xi\|_1 + \sqrt{m}\|r\|_2  = \frac{1}{2}\|\xi\|_1 + \frac{\sqrt{m}}{2}\|\xi\|_2 \leq  \frac{1}{2}\|\xi\|_1 + \frac{\sqrt{m}}{2}\|\xi\|_1,
   \]
   The first inequality is due to the triangle inequality of any norm. The second and third inequalities are due to the fact that for an \(m\) dimensional vector \(\xi\),
   \begin{align*}
   \|\xi\|_2\leq \|\xi\|_1 \leq  \sqrt{m}\|\xi\|_2.
   \end{align*}
   Without loss of generality, let us assume that \(\|\xi\|_1 = 1\).
   The achievability of \eqref{eq:parallel} is easy to verify. 
