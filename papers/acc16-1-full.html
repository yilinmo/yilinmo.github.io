---
layout: page
title: ! 'Convex Optimization Based State Estimation against Sparse Integrity Attacks'
comments: true
---
<hr />
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orga8bfb6f">1. Introduction</a>
<ul>
<li><a href="#orgf7f74ea">1.1. Related Work</a></li>
</ul>
</li>
<li><a href="#org6a48e4a">2. Problem Setup</a>
<ul>
<li><a href="#orgb980608">2.1. System Model</a></li>
<li><a href="#org030da65">2.2. A General Estimator</a></li>
</ul>
</li>
<li><a href="#org831ca8c">3. Robust Analysis for a General Estimator</a></li>
<li><a href="#orgb409971">4. Scalar Measurement Case: More Analysis</a></li>
<li><a href="#org8d52baa">5. Concluding Remarks</a></li>
<li><a href="#org926626a">6. Appendix</a>
<ul>
<li><a href="#org24487ab">6.1. Proof of Lemma lemma:1</a></li>
<li><a href="#org002e233">6.2. Proof of Lemma lemma:divergence</a></li>
<li><a href="#org4ff9375">6.3. Proof of Lemma lemma:l1decompose</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orga8bfb6f" class="outline-2">
<h2 id="orga8bfb6f"><span class="section-number-2">1</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
The concept of networks has been increasingly prevailing for decades, e.g., computer networks, sensor networks or social networks. Regardless of numerous benefits introduced by bridging machines or humans through networks, the interconnect and distributed nature renders networks vulnerable to various kinds of attacks, ranging from physical attacks to internet viruses to groundless rumors through online social networks. This article is concerned with the integrity attacks in sensor networks which are widely embedded in various industrial systems such as smart grid~\cite{MassoudAmin2005} or Supervisory Control And Data Acquisition (SCADA) systems~\cite{boyer2002scada}. During the integrity attack, the adversary can take full control of a subset of sensors and arbitrarily manipulate their measurements. The motivations for launching such an attack in industrial systems may include creating arbitrage opportunities in electricity market, stealing gas or oil without being noticed, posing potential threat to national defense, etc. Since the first SCADA system malware (called Stuxnet) was discovered and extensively investigated~\cite{Chen2010,Fidler2011}, increasing research attention has been paid to resolve the security issues in estimation and control systems~\cite{challengessecurity}.
</p>

<p>
In this article, we focus on the problem of robust estimation against compromised sensory data in order to mitigate the damage caused by the integrity attack. Robustness for an estimator is urgently needed since quite a number of the commonly used estimators under attack fail to give a reliable estimate and thus lead to poor system performance. For instance, a linear estimator is not robust since one bad measurement is enough to ruin the final estimate. A better estimator may be the geometric median of all measurements~\cite{Lopuhaa1991}. To be concrete, we consider the problem of estimating a vector state \(x\in\mathbb R^n\) from measurements collected by \(m\) sensors, where the measurements are subject to any random noise. For practical reasons, the spatially distributed sensors cannot be fully guaranteed to be secure. Some of them may be controlled by the attacker and due to the resource limitation the attacker can only attack up to \( p  \) sensors. Without posing any restrictions on the attacker, we assume that the compromised sensory data can be arbitrarily changed.
</p>
</div>

<div id="outline-container-orgf7f74ea" class="outline-3">
<h3 id="orgf7f74ea"><span class="section-number-3">1.1</span> Related Work</h3>
<div class="outline-text-3" id="text-1-1">
<p>
A quite similar problem in the context of power systems is bad data detection, which has been studied over the past decades~\cite{Handschin1975,Mili1985}. The method of checking the magnitude of residue is useful for identifying random bad data or outliers but may not work for intentional integrity attacks \cite{henrik2010,Xie2011}. For example, Liu et al.~\cite{liu2009} successfully showed that a stealthy attack changing the state while not being detected is possible. Kim et al.~\cite{Kim2014} studied a so-called framing attack. Under such a attack, the bad data detector is misled to delete those critical measurements, without which the network is unobservable and a convert attack may be launched.
</p>

<p>
For dynamical systems, detecting malicious components via fault detection and isolation based methods has also been extensively studied,  \cite{fp-ab-fb:09b,Pasqualetti2011,wirelesscontrol,Fawzi2012,chong2015observability}. However, in most of these works, the system is assumed to be noiseless, which greatly favors the failure detector. Pajic et al.~\cite{Pajic2014} improved the work by considering the systems with bounded noise. On the top of sufficient conditions for exact recovery in noiseless case, they showed that the worst error is still bounded even under attack. However, their estimator is based on a combinatorial optimization problem, which in general is computational hard to solve and may not be applicable for large scale systems. In \cite{Mo2010,moscs10security}, the authors use reachability analysis and ellipsoid approximation to characterize all possible biases the adversary can inject to the system.
</p>

<p>
In the area of statistics, the concept of robust estimators is not new~\cite{Kassam1985,robust2006,robust2009}. The robustness is often measured by breakdown points~\cite{Hampel1971,donoho1983notion} or influence functions~\cite{Hampel1974}. Many existing works studied one or several estimators and discussed the breakdown point properties \cite{Yohai2012,Rousseeuw1992,Hossjer1994,Rousseeuw2012}. However, a unified analysis for most useful estimators is still absent.
</p>


<p>
Motivated by different behaviors of various estimators under the integrity attacks, we manage to provide a unified robustness analysis framework integrating most commonly used estimators. To reach this goal, we first give a formal definition on the robustness of an estimator. To achieve greater generality, a general convex optimization based estimator is proposed and necessary and sufficient conditions on the robustness of such an estimator is proved. The significance of this work is that the analytical results presented in this manuscript can be used for characterizing and designing a robust estimator in the presence of compromised sensory data.
</p>


<p>
The rest of the paper is organized as follows. In Section <a href="#orgeb16ca4">2</a> we formulate the robust estimation problem. Our main results on the robustness of a general convex optimization based estimator is presented in Section <a href="#orgb0ad3e4">3</a>. We specialize our results for scalar sensor case in Section <a href="#orgc9481c7">4</a>. The concluding remarks are given in Section <a href="#orgd652c46">5</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-org6a48e4a" class="outline-2">
<h2 id="org6a48e4a"><span class="section-number-2">2</span> Problem Setup</h2>
<div class="outline-text-2" id="text-2">
<p>
<a id="orgeb16ca4"></a>
</p>
</div>

<div id="outline-container-orgb980608" class="outline-3">
<h3 id="orgb980608"><span class="section-number-3">2.1</span> System Model</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Assume that \(m\) sensors are measuring the state \(x\) and the measurement equation for the \(i\)th sensor is given by
</p>

\begin{align}
\label{eq:goodsystem}
z_i = H_i x + w_i,
\end{align}

<p>
where \(x\in\mathbb R^n\) is the state of interest, \(z_i\in \mathbb R^{m_i}\) is the ``true'' measurement collected by the \(i\)th sensor, and \(w_i \in \mathbb R^{m_i}\) is the measurement noise for the \(i\)th sensor. The measurement matrix \(H\triangleq [H_1^T,H_2^T,\ldots,H_i^T]^T\in\mathbb R^{(\sum_i m_i)\times n}\) is assumed to be observable, i.e., \(H\) is full column rank. In the presence of attacks, the measurement equation can be written as
</p>
\begin{align}
\label{eq:badsystem}
y_i = z_i + a_i = H_i x + w_i + a_i,
\end{align}
<p>
where \(y_i\in \mathbb R^{m_i}\) is the ``manipulated'' measurement and \(a_i\in \mathbb R^{m_i}\) is the attack vector. In other words, the attacker can change the measurement of the \(i\)th sensor by \(a_i\). Denote
</p>
\begin{align}
z&\triangleq[z_1^T,z_2^T,\ldots,z_m^T]^T, &
y&\triangleq[y_1^T,y_2^T,\ldots,y_m^T]^T, \\
w&\triangleq[w_1^T,w_2^T,\ldots,w_m^T]^T,&
a&\triangleq[a_1^T,a_2^T,\ldots,a_m^T]^T.\nonumber
\end{align}

<p>
Denote the index set of all sensors as \(\mathcal S\triangleq\{1,2,\ldots,m\}\). For any index set \(\mathcal I\subseteq \mathcal S\), define the complement set to be \(\mathcal I^c\triangleq \mathcal S\backslash\mathcal I\). In our attack model, we assume that the attacker can only compromise at most \(p\) sensors but can arbitrarily choose \(a_i\). Formally, a \((p,m)\)-sparse attack can be defined as
</p>

<div class="DEFINITION">
<p>
<b>\((p,m)\)-sparse attack</b>: A vector \(a\) is called a \((p,m)\)-sparse attack if there exists an index set \(\mathcal I\subset \mathcal S\), such that:
</p>

<ol class="org-ol">
<li>\(\left\|a_i\right\| = 0,~\forall i\in \mathcal I^c ;\)</li>
<li>\(\left|\mathcal I\right| \leq p.\)</li>
</ol>

</div>

<p>
Define the collection of a possible index set of malicious sensors as
\[
   \mathbb C\triangleq\{\mathcal I:\mathcal I\subset\mathcal S,\left|\mathcal I\right| = p\}.
   \]
The set of all possible \((p,m)\)-sparse attacks is denoted as
\[
   \mathcal A \triangleq \bigcup_{\mathcal I\in\mathbb C}\{a: \left\|a_i\right\| = 0, i\in \mathcal I^c\}.
   \]
</p>

<p>
The main task of this work is to investigate the generic sufficient and necessary conditions for an estimator to be robust to \((p,m)\)-sparse attacks. To this end, we first formally define the robustness of an estimator.
</p>

<div class="DEFINITION">
<p>
<b>Robustness</b>: An estimator \(g:\mathbb R^{(\sum_i m_i)\times n}\mapsto \mathbb R^n\) which maps the measurements \(y\) to a state estimate \(\hat x\) is said to be robust to the \((p,m)\)-sparse attack if it satisfies the following condition:
</p>
\begin{align}
\left\|g(z)-g(z+a)\right\|\leq \mu(z),~\forall a\in\mathcal A,\label{eq:defrobust}
\end{align}
<p>
where \(\mu:\mathbb R^{(\sum_i m_i)\times n}\mapsto \mathbb R\) is a real-valued mapping on \(z\).
</p>

</div>

<p>
The robustness implies that the disturbance on the state estimate caused by an arbitrary attack is bounded. A trivial robust estimator is \(g(y)=0\) which provides very poor estimate. Therefore, another desirable property for an estimator is translation invariance, which is defined as follows:
</p>

<div class="DEFINITION">
<p>
<b>Translation invariance</b>: An estimator \(g\) is translation invariant if \(g(z+Hu)=u+g(z),~\forall u\in\mathbb R^n\).
</p>

</div>

<div class="REMARK">
<p>
Notice that if an estimator is robust and translation invariant, then
</p>
\begin{align*}
\| g(z) - g(z+a) \|= \|x + g(w) - x + g(w+a) \|  = \|g(w)-g(w+a)\|\leq \mu(w).
\end{align*}
<p>
Therefore, the maximum bias that can be injected by an adversary is only a function of the noise \(w\).
</p>

</div>

<p>
In the next subsection, we propose a general convex optimization based estimator which is translation invariant.
</p>
</div>
</div>

<div id="outline-container-org030da65" class="outline-3">
<h3 id="org030da65"><span class="section-number-3">2.2</span> A General Estimator</h3>
<div class="outline-text-3" id="text-2-2">
<p>
A large variety of estimators are developed by the research community to solve the state estimation problem. In order to achieve greater generality, we first propose a general convex optimization based estimator. We then show that many estimators can be rewritten in this general framework.
</p>

<p>
The estimator that we study in this paper is assumed to have the following form:
</p>
\begin{align}
\hat x = g(y) \triangleq \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S} f_i(y_i-H_i\hat x),
\label{eq:general}
\end{align}
<p>
where the following properties of function \(f_i:\mathbb R^{m_i}\mapsto \mathbb R\) are assumed:
</p>

<ol class="org-ol">
<li>\(f_i\) is convex.</li>
<li>\(f_i\) is symmetric, i.e., \(f_i(u) = f_i(-u)\).</li>
<li>\(f_i\) is non-negative and \(f_i(0) = 0\).</li>
</ol>

<div id="remark:1" class="REMARK">
<p>
It is easy to check that the estimator \(g\) is translation invariant. One can view \(y_i-H_i\hat x\) as the residue for the \(i\)th sensor and \(f_i\) as a cost function. The convex constraints on \(f_i\) ensures that the minimization problem can be solved in an efficient (possibly also distributed) way. The symmetric assumption on \(f_i\) is typically true for many practically used estimator and can actually be relaxed. The last assumption implies that the cost achieves minimum value when the residue is \(0\).
</p>

</div>

<p>
We now investigate several commonly used estimator and show that they can be written as \eqref{eq:general}.
</p>

<ul class="org-ul">
<li>Least Square Estimator:</li>
</ul>
\begin{align}
\hat x &=  \mathop{argmin}_{\hat x} \left\|y-H\hat x\right\|_2^2=  \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S}\left\|y_i-H_i\hat x\right\|_2^2\nonumber\\
& = (H^T H)^{-1}H^T y.
\label{eq:lsestimator}
\end{align}
<ul class="org-ul">
<li>Another example is an estimator which minimizes the sum of the \(l_1\) norm of the residue, i.e.,</li>
</ul>
\begin{align}
\hat x = \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S}\left\|y_i-H_i\hat x\right\|_1.  \label{eq:medianestimator}
\end{align}
<p>
In the case that \(m_i=n\) and \(H_i=I_n,~\forall i\), the estimate is a vector in which the \(i\)th entry is the median over the \(i\)th entries of all measurements \(y_i\)'s.
</p>

<ul class="org-ul">
<li>The following is designed to minimize the sum of the \(l_2\) norm of the residue:</li>
</ul>
\begin{align}
\hat x = \mathop{argmin}_{\hat x} \sum_{i\in\mathcal S}\left\|y_i-H_i\hat x\right\|_2.  
\label{eq:geometricmedianestimator}
\end{align}
<p>
The optimal estimate in the case that \(m_i=n\) and \(H_i=I_n,~\forall i\) is the geometric median of all \(y_i\)'s, which is called an \(L_1\) estimator in \cite{Lopuhaa1991}. In other words, \(\hat x\) is the point in \(\mathbb R^n\) that minimizes the sum of Euclidean distances from \(y_i\) to that point.
</p>
<ul class="org-ul">
<li>Pajic et al.~\cite{Pajic2014} proposed the following robust estimator in the presence of integrity attack:</li>
</ul>
\begin{align*}
& \mathop{\textit{minimize}}\limits_{\hat x,a,w}&
& \|w\|^2\\
&\text{subject to}&
&y = H\hat x + w + a,\,\|a\|_0\leq q.
\end{align*}
<p>
However, the minimization problem involves zero-norm, and thus is difficult to solve in general. A commonly adopted approach is to use \(L_1\) relaxation to approximate zero-norm, which leads to the following minimization problem:
</p>
\begin{align}
& \mathop{\textit{minimize}}\limits_{\hat x,a,w}&
& \|w\|^2+\lambda \|a\|_1\label{eq:optlasso}\\
&\text{subject to}&
&y = H\hat x + w + a.\nonumber
\end{align}
<p>
If we define the following function:
</p>
\begin{align}
d(u)~\triangleq ~&\mathop{\textit{minimize}}\limits_{a_i}&
&  \left\|u-a_i\right\|_2^2 + \lambda  \left\|a_i\right\|_1 \label{eq:lasso2}
\end{align}
<p>
Then one can easily prove that the optimization problem \eqref{eq:optlasso} can be rewritten as
</p>
\begin{align}
\hat x = \mathop{argmin}_{\hat x} \sum_{i\in\mathcal I} d(y_i - H_i \hat x).\label{eq:lasso}
\end{align}

<p>
In the next section, we shall present sufficient and necessary conditions for the robustness of the general estimator \eqref{eq:general}. Since \eqref{eq:medianestimator}, \eqref{eq:geometricmedianestimator} and \eqref{eq:lasso} are all special cases of \eqref{eq:general}, we can easily analyze their individual robustness.
</p>
</div>
</div>
</div>


<div id="outline-container-org831ca8c" class="outline-2">
<h2 id="org831ca8c"><span class="section-number-2">3</span> Robust Analysis for a General Estimator</h2>
<div class="outline-text-2" id="text-3">
<p>
<a id="orgb0ad3e4"></a>
This section is devoted to the derivation of necessary and sufficient conditions for the robustness of the general estimator.
</p>

<p>
Denote the compact set \(\mathcal U\triangleq\{u\in \mathbb R^n:\left\|u\right\|= 1\}\). Before proceeding to the main results, we need the following lemma.
</p>

<div id="lemma:convex" class="LEMMA">
<p>
Let \(q:\mathbb R\rightarrow \mathbb R\) be a convex function and \(q(0) = 0\), then \(q(t)/t\) is monotonically non-decreasing on \(t\in \mathbb R^+\). Moreover,
</p>
\begin{align}
q(t+1)-q(t)\geq q(t)/t.
\label{eq:marginalincrease}
\end{align}

</div>

<div class="PROOF">
<p>
For any \(0 < \alpha < 1\), we have
</p>
\begin{align*}
q(\alpha t) \leq \alpha q(t) + q(0) = \alpha q(t).
\end{align*}
<p>
Divide both side by \(\alpha t\), we can prove that \(q(t)/t\) is monotonically non-decreasing. Therefore, \(q(t+1)/(t+1)\geq q(t)/t\), which implies \eqref{eq:marginalincrease}.
</p>

</div>
<p>
As a consequence of Lemma <a href="#org8c99b0f">1</a>, we know that \(f_i(tH_iu)/t\) is monotonically non-decreasing. As a result, there are only two possibilities:
</p>

<ol class="org-ol">
<li>\(f_i(tH_iu)/t\) is bounded for all \(i\) and for all \(u\), which implies that the limit \(\lim_{t\rightarrow\infty}f_i(tH_iu)/t\) exists.</li>
<li>\(f_i(tH_iu)/t\) is unbounded for some \(i\) and \(u\).</li>
</ol>

<p>
The next lemma provides several important properties for the case where \(\lim_{t\rightarrow\infty}f_i(tH_iu)/t\) exists, whose proof is reported in the appendix:
</p>

<div id="lemma:1" class="LEMMA">
<p>
If the following limit is well defined, i.e., finite, for all \(u\in \mathbb R^{n}\):
</p>
\begin{align}
\lim_{t\rightarrow\infty} \frac{f_i(tH_iu)}{t} = C_i(u),
\label{eq:sublinear}
\end{align}
<p>
then the following statements are true:
</p>

<ul class="org-ul">
<li>\(C_i(\alpha u)=\left|\alpha\right| C_i(u)\) and \(C_i(u_1+u_2)\leq C_i(u_1)+C_i(u_2)\).</li>
<li>Define the function \(h_i(u,v,t):\mathbb R^n\times\mathbb R^{m_i}\times \mathbb R\mapsto\mathbb R\),</li>
</ul>
\begin{align}
h_i(u,v,t) \triangleq \frac{1}{t}\left[f_i(v+tH_iu)-f_i(v)\right].\label{eq:defhfunction}
\end{align}
<p>
Then the following pointwise limit holds:
</p>
\begin{align}
\lim_{t\rightarrow\infty}h_i(u,v,t)  = C_i(u).
\label{eq:deltalimit}
\end{align}
<p>
Moreover, the convergence is uniform on any compact set of \((u,v)\).
</p>
<ul class="org-ul">
<li>For any \(v\) and \(u\), we have that</li>
</ul>
\begin{align}
f_i(v+H_iu) - f_i(v) \leq C_i(u).
\label{eq:deltaw}
\end{align}

</div>

<div id="remark:force" class="REMARK">
<p>
Intuitively speaking, one can interpret \(f_i\) as a potential field and the derivative of \(f_i\) as the force generated by sensor \(i\) (if it is differentiable). By \eqref{eq:deltaw}, we know that the force from the potential field \(f_i\) along the \(u\) direction cannot exceed \(C_i(u)\) (or \(C_i(u)/\|u\|\) to normalize). On the other hand, Equation \eqref{eq:deltalimit} implies that this bound is achievable.
</p>

</div>

<p>
We now give the sufficient condition for the robustness of the estimator.
</p>

<div id="theorem:sufficient" class="THEOREM">
<p>
If the following conditions hold:
</p>

<ul class="org-ul">
<li>\(C_i(u)\) is well defined for all \(u\in \mathbb R^{n}\) and all \(i\in\mathcal S\);</li>
<li>the following inequality holds for all non-zero \(u\):</li>
</ul>
\begin{align}
\sum_{i\in\mathcal I}C_i(u)<\sum_{i\in\mathcal I^c}C_i(u),~\forall \mathcal I \in\mathbb C,\label{eq:sufficiency}
\end{align}

<p>
then the estimator \(g\) is robust.
</p>

</div>

<div class="PROOF">
<p>
Our goal is to prove that there exists a \(\beta(z)\), such that for any \(t\geq \beta(z)\), \(\|u\| = 1\), \(a\in\mathcal A\), the following inequality holds:
</p>
\begin{align}
\sum_{i\in\mathcal S}f_i(y_i - H_i\times tu) < \sum_{i\in\mathcal S} f_i(y_i-H_i\times (t+1)u).
\label{eq:sufficientdiff}
\end{align}
<p>
As a result, any point \(\|\hat x\| \geq \beta(z)+1\) cannot be the solution of the optimization problem since there exists a better point \((\|\hat x\|-1)\hat x/\|\hat x\|\). Therefore, we must have \(\|g(y)\|\leq \beta(z) + 1\) and hence the estimator is robust.
</p>

<p>
Suppose the set of malicious sensors is \(\mathcal I\), to prove \eqref{eq:sufficientdiff}, we will first look at benign sensors. Due to the uniform convergence of \(h_i(u,v,t)\) to \(C_i(u)\) on \(\mathcal U\times\{-z_i\}\) shown in Lemma <a href="#org6ff5215">1</a>, given any \(\delta>0\) we can always find a finite constant \(N_i\) depending on \(\delta\) and \(z_i\) such that for all \(t \geq N_i(\delta,z_i)\), the following inequality holds:
</p>
\begin{align}
h_i(-z_i,u,t) = \frac{1}{t}\left[f_i(tH_iu-z_i)-f_i(-z_i)\right]\geq C_i(u) - \delta,
\label{eq:deltaapprox2}
\end{align}
<p>
for any \(\|u\|=1\). By \eqref{eq:marginalincrease}, we can derive that
</p>
\begin{align}
f_i((t+1)H_iu-z_i)-f_i(tH_iu-z_i)\geq C_i(u) - \delta.
\label{eq:deltaapprox3}
\end{align}
<p>
We define \(\beta(z) \triangleq \max_{1\leq i\leq m} N_i(\delta,z_i)\) and fix \(\delta\) to be
</p>
\begin{align}
\delta = \frac{1}{m}\min_{\|u\|=1}\min_{\mathcal I\in\mathbb C}\left(\sum_{i\in\mathcal I^c}C_i(u) - \sum_{i\in\mathcal I}C_i(u)\right).\label{eq:defdelta}
\end{align}
<p>
Notice that we write \(\min_{\|u\|=1}\) instead of \(\inf_{\|u\|=1}\) since \(C_i(u)\) is continuous and the set \(\{u:\|u\|=1\}\) is compact. Hence, the infimum is achievable, which further proves that \(\delta > 0\) is strictly positive. Hence, for \(i = 1,\dots,m\), if \(t > \beta_{\delta}(z)\) we have
</p>
\begin{equation}
f_i((t+1)H_iu-z_i)-f_i(tH_iu-z_i) \geq C_i(u) - \delta,\,\forall \|u\|=1.
\end{equation}
<p>
Since for good sensors, \(z_i = y_i\), we know that
</p>
\begin{align}
\sum_{i\in \mathcal I^c} & \left[f_i((t+1)H_iu-z_i)-f_i(tH_iu-z_i)\right]\nonumber\\
&\geq  \sum_{i\in \mathcal I^c} C_i(u) -(m-p) \delta,\,\forall \|u\|=1.
\label{eq:suff2}
\end{align}
<p>
We now consider malicious sensors. By Lemma <a href="#org6ff5215">1</a> (iii), we know that for \(i\in\mathcal I\), and any \(u\)
</p>
\begin{align}
\sum_{i\in\mathcal I} f_i(y_i - t H_i u)  - \sum_{i\in\mathcal I} f_i(y_i- (t +1)H_i u)\leq \sum_{i\in\mathcal I}C_i(-u).\label{eq:suff1}
\end{align}
<p>
Hence from \eqref{eq:defdelta}, \eqref{eq:suff1} and \eqref{eq:suff2}, we know that
</p>
\begin{align*}
\sum_{i\in\mathcal S} f_i(y_i &- (t+1) H_i u) - \sum_{i\in\mathcal S} f_i(y_i - t H_i u) \\
&\geq \sum_{i\in\mathcal I^c}C_i(u) - \sum_{i\in\mathcal I}C_i(u) - (m-p)\delta > 0,
\end{align*}
<p>
which proves \eqref{eq:sufficientdiff}.
</p>

</div>

<div class="REMARK">
<p>
Assuming that \(y_i\) is a scalar and \(w=0\), Fawzi et al.~\cite{Fawzi2012} prove that the state can be exactly recovered under the integrity attack if and only if for all \(u\neq 0\), there are at least \(2p+1\) non-zero \(H_iu\). Notice that if for some \(u\neq 0\), there are less than \(2p+1\) non-zero \(H_iu\), then we can choose \(\mathcal I\) to contain the largest \(p\) \(H_iu\) and thus violate \eqref{eq:sufficiency}. As a result, our sufficient condition is stronger than the ones proposed in \cite{Fawzi2012}. The main reason is that we seek to use convex optimization to solve the state estimation problem, while in \cite{Fawzi2012}, a combinatorial optimization problem is needed to recover the state.
</p>

</div>

<p>
We next give necessary conditions for the robustness of the estimator.
</p>

<div id="theorem:necessity1" class="THEOREM">
<p>
<b>Necessary Condition I</b>: If \( C_i(u)\) is well defined for all \(u\in \mathbb R^{n}\) and all \(i\in\mathcal S\) but there exist some \(\|u_0\|=1,~\mathcal I_0\in\mathbb C\) such that
</p>
\begin{align}
\sum_{i\in\mathcal I_0}C_i(u_0)>\sum_{i\in\mathcal I_0^c}C_i(u_0),\label{eq:necessity}
\end{align}
<p>
then the estimator is not robust to the attack.
</p>

</div>

<div class="PROOF">
<p>
The robustness of the estimator is equivalent to that the optimal estimate \(\hat x\) satisfies \(\left\|\hat x\right\|\leq \mu(z)\) for all \(a\in \mathcal A\), where \(\mu\) is a real-valued function. To this end, we will prove that for any \(r > 0\), there exists a \(y\) such that all \(\hat x\) that satisfies \(\left\|\hat x\right\|\leq r\) cannot be the optimal solution of \eqref{eq:general}.
</p>

<p>
We will first look at the compromised sensors. For every \(\delta>0\) we can always find a finite constant \(N_i(\delta)\) such that for any \(\hat x\in\{\hat x:\left\|\hat x\right\|\leq r\}\) and for all \(t > N_i\), the following inequality holds:
</p>
\begin{align}
&f_i(t H_iu_0-H_i\hat x)-f_i(tH_iu_0 - H_i(\hat x+u_0)) \nonumber\\
&f_i((t+1) H_iu_0-H_i(\hat x+u_0))-f_i(tH_iu_0 - H_i(\hat x+u_0)) \nonumber\\
\geq & h_i(u_0,-H_i(\hat x+u_0),t)\geq C_i(u_0)-\delta,~\forall i\in \mathcal I_{0}. \label{eq:nece1}
\end{align}
<p>
The first inequality is derived from \eqref{eq:marginalincrease}. The second inequality is due to the uniform convergence of \(h_i(u,v,t)\) to \(C_i(u)\) on \(\{u_0\}\times \{v:v=-H_ix+u_0,\,\|x\|\leq  r\}\).
</p>

<p>
Let us choose
</p>
\begin{align*}
\delta = \frac{1}{m}\left(\sum_{i\in\mathcal I_{0}}C_i(u_0) - \sum_{i\in \mathcal I_{0}^c}C_i(u_0)\right),
\end{align*}
<p>
and \(t = \max_{i\in\mathcal I_0} N_i(\delta)\) and \(y_i = tH_iu_0\) for all \(i\in \mathcal I_0\), then we know for any \(\|\hat x\|\leq  r\),
\[
\sum_{i\in\mathcal I_0}\left[f_i(y_i-H_i\hat x)-f_i(y_i - H_i(\hat x+u_0))\right]  \geq \sum_{i\in \mathcal I_0} C_i(u_0)-p\delta.
\]
Now let us look at the benign sensors. By Lemma <a href="#org6ff5215">1</a> (iii) we have
</p>
\begin{equation}
f_i(z_i-H_i(\hat x+u_0))-f_i(z_i-H_i\hat x)  \leq  C_i(u_0),~\forall i\in \mathcal I\backslash \mathcal I_{m_0}.\label{eq:nece2}
\end{equation}
<p>
From \eqref{eq:nece1} and \eqref{eq:nece2},
</p>
\begin{equation}
\sum_{i\in\mathcal S} f_i(y_i-H_i(\hat x+u_0))  - \sum_{i\in\mathcal S} f_i(y_i-H_i\hat x) \leq \sum_{i\in\mathcal I_0^c}C_i(u_0) - \sum_{i\in\mathcal I_{0}}C_i(u_0) + p\delta < 0.
\end{equation}
<p>
Thus for such a \(y\) satisfying
</p>
\begin{align*}
 y_i= \left\{
\begin{array}{ll}
z_i, & \hbox{if } i\in\mathcal I_0^c\\
tH_iu_0, & \hbox{if } i\in\mathcal I_{0},
\end{array}
\right.
\end{align*}
<p>
\(\hat x+u_0\) is a better estimate than all \(\hat x\) satisfying \(\left\|\hat x\right\|\leq  r\). Since \(r\) is an arbitrary positive real number, we can conclude that the estimator is not robust.
</p>

</div>

<div id="theorem:necessity2" class="THEOREM">
<p>
<b>Necessary Condition II</b>: If there exists \(u_0 \in \mathbb R^{n}\) and \(j\in \mathcal I\) such that
</p>
\begin{align}
\lim_{t\rightarrow\infty} \frac{f_i(tH_iu_0)}{t}\rightarrow +\infty,
\label{eq:sublinear2}
\end{align}
<p>
then the estimator is not robust to the attack.
</p>

</div>
<p>
Before proving Theorem <a href="#org4e07d07">1</a>, we need the following lemma whose proof is reported in appendix.
</p>

<div id="lemma:divergence" class="LEMMA">
<p>
If the condition \eqref{eq:sublinear2} holds, for any \(M>0\) and for all \(v\) in a compact set \(\mathcal V\subset \mathbb R^{m_i}\), there exists \(N\) (depending on \(M\) and the set \(\mathcal V\)) such that the following inequality holds:
</p>
\begin{align}
h_j(u_0,v,t)>M,\,\forall v\in \mathcal V\label{eq:divergence}
\end{align}

</div>

<p>
Now we are ready to prove the theorem.
</p>

<div class="PROOF">
<p>
Similar to Theorem <a href="#orge90969c">1</a>, we will prove that for any \(r > 0\), there exists a \(y\) such that all \(\hat x\) that satisfies \(\left\|\hat x\right\|\leq r\) cannot be the optimal solution of \eqref{eq:general}.
</p>

<p>
We first look at any sensor \(i\), where \(i\neq j\). Since a continuous function achieves its supremum on a compact set, we know that the following supremum is well defined (not infinite)
</p>
\begin{align*}
\sup_{\|\hat x\|\leq r}\left[f(z_i - H_i(\hat x+u_0)) - f(z_i - H_i\hat x)\right] = M_i,
\end{align*}
<p>
which implies that for all \(\|\hat x\|\leq r\), we can find \(M > 0\), such that
</p>
\begin{align}
\sum_{i\neq j} f(z_i - H_i(\hat x+u_0)) - \sum_{i\neq j} f(z_i - H_i\hat x) \leq M.
\label{eq:divergence1}
\end{align}

<p>
Now let us consider sensor \(j\). Due to Lemma <a href="#org91fb44f">1</a>, we can find a \(t\), such that for all \(\|\hat x\|\leq r\), the following inequality holds:
</p>
\begin{align*}
h_j(u_0,-H_j(\hat x + u_0),t) > M.
\end{align*}

<p>
Using Lemma <a href="#org8c99b0f">1</a>, we have
</p>
\begin{align}
&f((t+1)H_ju_0 - H_j(\hat x + u_0)) - f(t H_ju_0 - H_j(\hat x + u_0))\nonumber\\
& = f(tH_ju_0 - H_j\hat x) - f(t H_ju_0 - H_j(\hat x + u_0))\nonumber\\
& \geq h_j(u_0,-H_j(\hat x + u_0),t) > M.\label{eq:divergence2}
\end{align}
<p>
Now consider the following \(y\)
</p>
\begin{align*}
 y_i= \left\{
\begin{array}{ll}
z_i, & \hbox{if } i\neq j\\
tH_ju_0, & \hbox{if } i=j,
\end{array}
\right.
\end{align*}

<p>
Combining \eqref{eq:divergence1} and \eqref{eq:divergence2}, we know that for all \(\|\hat x\|\leq r\), the following inequality holds
</p>
\begin{align*}
\sum_{i\in\mathcal S} f(y_i - H_i(\hat x+u_0)) - \sum_{i\in\mathcal S} f(y_i - H_i\hat x) < M - M =0,
\end{align*}
<p>
which implies that the optimal solution of \eqref{eq:general} cannot be inside the ball \(\{\hat x:\|\hat x\|\leq r\}\). Now since \(r > 0\) is arbitrary, we know the estimator is not robust.
</p>

</div>
<p>
Before continuing on, we would like to provide some remarks on the main result. First, it is worth noticing that the existence of a well defined limit of \(f_i(tH_iu)/t\) is crucial for the robustness of \(g\) as Theorem <a href="#org4e07d07">1</a> suggested. For example, the least square estimator cannot be robust since \(f_i\) is in quadratic form. Using the potential field and force analogies in Remark <a href="#org8902d2d">1</a>, one can interpret the results presented in this section as: the estimator \(g\) is robust if the force generated by any sensor is bounded and if the combined force of any collection of \(p\) sensors is no greater than the combined force of the remaining \(m-p\) sensors.
</p>

<p>
Secondly, one can see that the conditions proved in Theorem <a href="#orgbf20f58">1</a>, <a href="#orge90969c">1</a> and <a href="#org4e07d07">1</a> are very tight, with only a trivial gap where the LHS of \eqref{eq:necessity} equals the RHS.
</p>

<p>
Finally, we want to point out that the condition \eqref{eq:sufficiency} is non-trivial to check since it requires us to verify against all possible \(u\). In the next subsection, we consider a special case where each \(y_i\) is a scalar and provide a more conservative but verifiable sufficient condition for the robustness of the estimator.
</p>
</div>
</div>

<div id="outline-container-orgb409971" class="outline-2">
<h2 id="orgb409971"><span class="section-number-2">4</span> Scalar Measurement Case: More Analysis</h2>
<div class="outline-text-2" id="text-4">
<p>
<a id="orgc9481c7"></a>
In this section, we specialize our results to the scalar measurement case, i.e., \(m_i=1,~\forall i\in \mathcal S\). Throughout this section, we assume that the following limit is well-defined:
</p>
\begin{align}
\alpha_i \triangleq \lim_{t\rightarrow\infty} f_i(t)/t.
\end{align}
<p>
It is not difficult to prove that \(C_i(u) = \left|\alpha_i H_i u\right|\). With slight abuse of notation, define \(C_i \triangleq \alpha_i H_i\), then \(C_i(u) = \left|C_iu\right|\). For any index set \(\mathcal I = \{i_1,\dots,i_l\}\subset \mathcal S\), define
</p>
\begin{align}
C_{\mathcal I} \triangleq \begin{bmatrix}
C_{i_1}\\
\vdots\\
C_{i_l}
\end{bmatrix}.
\end{align}

<p>
From Theorem <a href="#orgbf20f58">1</a> and Theorem <a href="#orge90969c">1</a>, we have the following sufficient and necessary conditions for robustness of \(g\).
</p>

<div id="prop:scalarsuffandnece" class="PROPOSITION">
<ul class="org-ul">
<li>If for all possible index set \(\mathcal I\) and all non-zero \(u\in\mathbb R^n\) the following inequality holds:</li>
</ul>
\begin{align}
\|C_{\mathcal I}u\|_1= \sum_{i\in\mathcal I}|C_{i} u |<  \sum_{i\in\mathcal I^c}|C_{i} u| = \|C_{\mathcal I^c}u\|_1, \label{eq:suff3}
\end{align}
<p>
then the estimator \(g\) is robust.
</p>
<ul class="org-ul">
<li>If there exists an index set \(\mathcal I\) and a \(u\in\mathbb R^n\) such that the following inequality holds:</li>
</ul>
\begin{align}
\|C_{\mathcal I}u\|_1 > \|C_{\mathcal I^c}u\|_1, \label{eq:suff4}
\end{align}
<p>
then the estimator \(g\) is not robust.
</p>

</div>

<p>
The main difficulty here is to validate \eqref{eq:suff3} for all non-zero \(u\). In the next theorem, we can find a more conservative but more practically useful sufficient condition for the robustness, by eliminating \(u\) from \eqref{eq:suff3}.
</p>

<div id="theorem:scalarsuff" class="THEOREM">
<p>
If for any index set \(\mathcal I\subset \mathcal S\) with cardinality \(p\), the optimal value of the following optimization problem is strictly less than \(1\):
</p>
\begin{align}
&\mathop{\textrm{minimize}}\limits_{K\in\mathbb R^{n\times{(m-p)}}}&
& \|C_{\mathcal I}K\|_1\nonumber\\
&\textrm{subject to}&
& KC_{\mathcal I^c} = I_n,\label{eq:scalarsufficient}
\end{align}
<p>
then the estimator \(g\) is robust.
</p>

</div>

<div class="PROOF">
<p>
Let \(K\in\mathbb R^{n\times (m-p)}\) such that \(K C_{\mathcal I^c} = I_n\). Denote \(\xi=C_{\mathcal I^c} u\). We have \(C_{\mathcal I} u = C_{\mathcal I} K \xi\). Therefore, if for all \(\xi\neq 0\), \(\left\|C_{\mathcal I}\right\| K \xi_1 < \left\|\xi\right\|_1\), i.e., \(\left\|C_{\mathcal I}\right\|K_1 < 1\), then
</p>
\begin{align*}
\|C_{\mathcal I}u\|_1 <  \|C_{\mathcal I^c}u\|_1.
\end{align*}
<p>
By enumerating all possible \(\mathcal I\) we can conclude the proof.
</p>

</div>

<p>
Notice that \eqref{eq:scalarsufficient} is not necessary. Since \(\xi\) is in the column space of \(C_{\mathcal I^c}\), \(\xi\) may not be able to take all possible value in \(\mathbb R^{m-p}\).
</p>

<p>
Similarly, we can find a more practically useful version for the necessary condition implied by Theorem <a href="#orge90969c">1</a>. By enumerating all \((C_{\mathcal I},C_{\mathcal I^c})\) and utilizing the following result, we can identify whether \(g\) is robust for a given \(H\) or not.
</p>

<div id="theorem:scalarnecessity" class="THEOREM">
<p>
If there exists an index set \(\mathcal I\) such that the following inequality holds:
</p>
\begin{align}
\|C_{\mathcal I}C_{\mathcal I^c}^+\|_1 > (\sqrt{m-p}+1)/2,\label{eq:nece3}
\end{align}
<p>
where \(C_{\mathcal I^c}^+\) is the Moore-Penrose pseudo inverse of \(C_{\mathcal I^c}\), then the estimator \(g\) is not robust.
</p>

</div>
<p>
The following lemma, whose proof is given in the appendix, is needed for the proof of Theorem <a href="#org30bea09">1</a>:
</p>

<div id="lemma:l1decompose" class="LEMMA">
<p>
Let \(\xi\in\mathbb R^m\) such that \(\xi = \xi_{\parallel} + \xi_{\perp}\), where \(\xi_{\|}\) and \(\xi_\perp\) are perpendicular to each other. Then the following inequality holds:
</p>
\begin{align}
\|\xi_\|\|_1 \leq \frac{\sqrt{m}+1}{2}\|\xi\|_1.
\label{eq:parallel}
\end{align}
<p>
Moreover, the above inequality is achievable when
</p>
\begin{align*}
\xi =  \begin{bmatrix}
1\\
0\\
\vdots\\
0
\end{bmatrix}, \,\xi_\|=\frac{1}{2}\begin{bmatrix}
1+m^{-1/2}\\
m^{-1/2}\\
\vdots\\
m^{-1/2}
\end{bmatrix}, \,\xi_\perp=\frac{1}{2}\begin{bmatrix}
1-m^{-1/2}\\
-m^{-1/2}\\
\vdots\\
-m^{-1/2}
\end{bmatrix}.
\end{align*}

</div>


<p>
We are now ready to prove Theorem <a href="#org30bea09">1</a>:
</p>
<div class="PROOF">
<p>
To prove \(g\) is not robust, from Proposition <a href="#org9c32012">1</a> we only need to show there exists a \(u\) such that \(\|C_{\mathcal I}u\|_1 > \|C_{\mathcal I^c} u\|_1\) if \eqref{eq:nece3} holds.
Since \(\left\|C_{\mathcal I}C_{\mathcal I^c}^+\right\|_1>(\sqrt{m-p}+1)/2\), we can find \(\xi\in \mathbb R^{m-p}\), such that
</p>
\begin{align*}
\left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi\right\|_1 >\frac{\sqrt{m-p}+1}{2}\left\|\xi\right\|_1.
\end{align*}

<p>
Now we can decompose \(\xi = \xi_\|+\xi_\perp\), where \(\xi_\|\) belongs to the column space of \(C_{\mathcal I^c}\) and \(\xi_\perp\) is perpendicular to the column space of \(C_{\mathcal I^c}\). By the property of Moore-Penrose inverse, \(C_{\mathcal I^c}^+\xi_\perp = 0\). Therefore,
</p>
\begin{align*}
\left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi\right\|_1 = \left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi_\|\right\|_1.
\end{align*}
<p>
On the other hand, since \(\xi\in \mathbb R^{m-p}\), by Lemma <a href="#org733dc5b">1</a>, we have
</p>
\begin{align*}
\frac{\sqrt{m-p}+1}{2}\left\|\xi\right\|_1\geq \left\|\xi_\|\right\|_1,
\end{align*}
<p>
which implies that
</p>
\begin{align*}
\left\|C_{\mathcal I}C_{\mathcal I^c}^+\xi_\|\right\|_1 >\left\|\xi_\|\right\|_1.
\end{align*}
<p>
Since \(\xi_\|\) belongs to the column space of \(C_{\mathcal I^c}\), there exists a \(u\), such that \(C_{\mathcal I^c} u = \xi_\|\). Therefore, we can find a \(u\), such that
</p>
\begin{align*}
\left\|C_{\mathcal I}u\right\|_1 > \left\|C_{\mathcal I^c}u\right\|_1,
\end{align*}
<p>
which completes the proof.
</p>

</div>
</div>
</div>

<div id="outline-container-org8d52baa" class="outline-2">
<h2 id="org8d52baa"><span class="section-number-2">5</span> Concluding Remarks</h2>
<div class="outline-text-2" id="text-5">
<p>
  <a id="orgd652c46"></a>
We have studied the robust estimation problem where \(p\) out of \(m\) sensors are under attack. The malicious measurements can be arbitrarily manipulated and thus a robust estimator which can give a reliable estimate is needed. Our interest is not to study any concrete estimator in presence of attacks. Instead, we have considered a general class of estimators which integrate a large number of important estimators as special cases and given sufficient and necessary conditions for the robustness of the estimator. Moreover, we have presented more analytical results in the scalar measurement case to render the sufficient and necessary conditions more ready to use. Future works include the robustness analysis for the dynamical state estimation problem.
</p>
</div>
</div>
<div id="outline-container-org926626a" class="outline-2">
<h2 id="org926626a"><span class="section-number-2">6</span> Appendix</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org24487ab" class="outline-3">
<h3 id="org24487ab"><span class="section-number-3">6.1</span> Proof of Lemma <a href="#org6ff5215">1</a></h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>If \(\alpha = 0\), then clearly \(C_i(0)= 0\). On the other hand, if \(\alpha\neq 0\), from the definition in \eqref{eq:sublinear}, we have</li>
</ul>
\begin{align*}
C_i(\alpha u) &= \lim_{t\rightarrow\infty} \frac{1}{t}f_i(|\alpha|t H_i u)\\
&= \left|\alpha\right| \lim_{t\rightarrow\infty} \frac{1}{\left|\alpha\right| t}f_i(|\alpha| t H_i u)= \left|\alpha\right| C_i(u).
\end{align*}
<p>
Due to the scaling property of \(C_i(u)\) and the convexity of \(f_i\), we have
</p>
\begin{align*}
C_i(u_1+u_2)= 2C_i\left(\frac{u_1+u_2}{2}\right)\leq C_i(u_1) + C_i(u_2).
\end{align*}
<p>
Therefore, we know that \(C_i\) is actually a semi-norm on \(\mathbb R^n\)
</p>
<ul class="org-ul">
<li>Based on the convexity of \(f_i\), we obtain</li>
</ul>
\begin{align}
2f_i(\frac{tH_iu}{2})&\leq f_i(v+tH_iu) + f_i(-v),\label{eq:temp1}\\
f_i(tH_iu)&\geq 2f_i(\frac{2v+tH_iu}{2}) - f(2v).\label{eq:temp2}
\end{align}
<p>
Dividing both sides of \eqref{eq:temp1} and \eqref{eq:temp2} by \(t\) and taking limit over \(t\), we have
</p>
\begin{align}
C_i(u)&\leq \liminf_{t\rightarrow\infty}\frac{1}{t}f_i(v+tH_iu) +   \lim_{t\rightarrow\infty}\frac{1}{t}f_i(-v),\label{eq:liminf}\\
C_i(u)&\geq \limsup_{t\rightarrow\infty}\frac{2}{t}f_i(v+\frac{t}{2}H_iu) -   \lim_{t\rightarrow\infty}\frac{1}{t}f_i(2v).\label{eq:limsup}
\end{align}
<p>
Since \(\lim_{t\rightarrow\infty}f_i(-v)/t=\lim_{t\rightarrow\infty}f_i(2v)/t=0\), from \eqref{eq:limsup} and \eqref{eq:liminf} we have the following pointwise limit
</p>
\begin{align*}
\lim_{t\rightarrow\infty}h_i(u,v,t) = C_i(u).
\end{align*}
<p>
Notice that for a fixed \((u,v)\), by Lemma <a href="#org8c99b0f">1</a>, \(h(u,v,t)\) is monotonically non-decreasing with respect to \(t\). Furthermore, \(C_i(u)\) is continuous since it is a semi-norm. Therefore, by Dini's theorem~\cite{rudin1964principles}, \(h(u,v,t)\) converges uniformly to \(C_i(u)\) on a compact set of \((u,v)\).
</p>
<ul class="org-ul">
<li>By Lemma <a href="#org8c99b0f">1</a>, we have</li>
</ul>
<p>
\[
   f_i(v+H_iu)-f_i(v) = f_i(H_iu) \leq \lim_{t\rightarrow} \frac{f_i(tH_iu)}{t} = C_i(u).
   \]
</p>
</div>
</div>

<div id="outline-container-org002e233" class="outline-3">
<h3 id="org002e233"><span class="section-number-3">6.2</span> Proof of Lemma <a href="#org91fb44f">1</a></h3>
<div class="outline-text-3" id="text-6-2">
<p>
From \eqref{eq:sublinear2} and \eqref{eq:temp1}, it is easy to see that \(h_j(u_0,v,t)\) diverges to infinity for all \(v\), i.e.,
</p>
\begin{align}
  h_j(u_0,v,t)\rightarrow +\infty.\label{eq:temp3}
\end{align}
<p>
Next we will show this divergence is also uniform. Denote \(\mathcal W_t\triangleq\{v:h_j(u_0,v,t)>M\}\). Since \(h_j(u_0,v,t)\) is continuous (\(f_i\) is continuous due to convexity), each \(\mathcal W_t\) is open. By Lemma <a href="#org8c99b0f">1</a>, \(h_j(u_0,v,t)\) is monotonically non-decreasing in \(t\). Therefore, \(\mathcal W_t\subseteq \mathcal W_{t'}\) if \(t\leq t'\) . Since for each \(v\) there exists \(t\) such that \(h_j(u_0,v,t)>M\) from \eqref{eq:temp3},
</p>
\begin{align*}
  \bigcup_{t\geq 0}\mathcal W_t = \mathbb R^{m_i}.
\end{align*}
<p>
Therefore, the collection \(\{\mathcal W_t\}\) is an open cover for the compact subset \(\mathcal V\). Thus, we can find a finite cover \(\mathcal W_{t_1},\dots,\mathcal W_{t_l}\) that covers \(\mathcal V\), i.e.,
</p>
\begin{align}
  \mathcal V\subseteq \mathcal W_{t_1} \cup\mathcal W_{t_2} \cup\dots\cup \mathcal W_{t_l} .
  \label{eq:opencover}
\end{align}
<p>
Now we can define \(N = \max(t_1,\dots,t_l)\). Since \(\mathcal W_t\) is non-decreasing with respect to \(t\), the RHS of \eqref{eq:opencover} is \(\mathcal W_N\). For any \(t \geq N\), we have
</p>
\begin{align*}
  \mathcal V\subseteq \mathcal W_{N}\subseteq \mathcal W_t,
\end{align*}
<p>
which combined with the definition of \(\mathcal W_t\) finishes the proof. 
</p>
</div>
</div>

<div id="outline-container-org4ff9375" class="outline-3">
<h3 id="org4ff9375"><span class="section-number-3">6.3</span> Proof of Lemma <a href="#org733dc5b">1</a></h3>
<div class="outline-text-3" id="text-6-3">
<p>
Geometrically, \(\xi_{\|}\) can be written as \(\xi_{\|}=\xi/2 + r\), where \(r\in\{r:\|r\|_2 = \|\xi\|_2 /2\}\). As a result, we have
\[
   \|\xi_\|\|_1 \leq \frac{1}{2}\|\xi\|_1 + \|r\|_1 \leq \frac{1}{2}\|\xi\|_1 + \sqrt{m}\|r\|_2  = \frac{1}{2}\|\xi\|_1 + \frac{\sqrt{m}}{2}\|\xi\|_2 \leq  \frac{1}{2}\|\xi\|_1 + \frac{\sqrt{m}}{2}\|\xi\|_1,
   \]
The first inequality is due to the triangle inequality of any norm. The second and third inequalities are due to the fact that for an \(m\) dimensional vector \(\xi\),
</p>
\begin{align*}
\|\xi\|_2\leq \|\xi\|_1 \leq  \sqrt{m}\|\xi\|_2.
\end{align*}
<p>
Without loss of generality, let us assume that \(\|\xi\|_1 = 1\).
The achievability of \eqref{eq:parallel} is easy to verify. 
</p>
</div>
</div>
</div>
